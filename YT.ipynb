{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3092fc69-2c6f-446a-ae8f-092142510144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "os.environ[\"OPENAI_API_VERSION\"]='OPENAI_API_VERSION'\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"]='AZURE_OPENAI_API_KEY'\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"]='AZURE_OPENAI_ENDPOINT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f14ea6-e278-4a1b-8e0b-865b7a12d0e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-58a8ab4e81b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopenai\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopenai\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAzureOpenAIEmbeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexample_selectors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSemanticSimilarityExampleSelector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocument_loaders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mYoutubeLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "from langchain.openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.openai import AzureChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "import textwrap\n",
    "import openai\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=\"text-embedding-ada-002\",\n",
    "    openai_api_version=\"2023-05-15\"\n",
    ")\n",
    "\n",
    "# Function to create FAISS database from YouTube video URL\n",
    "def create_db_from_youtube_video_url(video_url: str) -> FAISS:\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "    transcript = loader.load()\n",
    "    \n",
    "    # Split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    docs = text_splitter.split_documents(transcript)\n",
    "    \n",
    "    # Create and return the FAISS vectorstore\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    return db\n",
    "\n",
    "\n",
    "# Function to get a response based on a query and the document database\n",
    "def get_response_from_query(db, query, k=4):\n",
    "    # Perform similarity search to find relevant documents\n",
    "    docs = db.similarity_search(query, k=k)\n",
    "    \n",
    "    # Join the page content of the retrieved documents into a single string\n",
    "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "    \n",
    "    # Initialize the AzureChatOpenAI model\n",
    "    llm = AzureChatOpenAI(model=\"gpt-35-turbo-16k\", temperature=0)\n",
    "    \n",
    "    # Create a prompt template for answering the question\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"question\", \"docs\"],\n",
    "        template=\"\"\"\n",
    "        You are a helpful assistant that can answer questions about YouTube videos based on the video's transcript.\n",
    "        Answer the following question: {question}\n",
    "        By searching the following video transcript: {docs}\n",
    "        Only use the factual information from the transcript to answer the question.\n",
    "        If you feel like you don't have enough information to answer the question, say \"I don't know.\"\n",
    "        Your answers should be verbose and detailed.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Set up the chain with the model and prompt\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    \n",
    "    # Get the response from the chain\n",
    "    response = chain.run(question=query, docs=docs_page_content)\n",
    "    \n",
    "    # Clean the response by removing newlines\n",
    "    response = response.replace(\"\\n\", \" \")\n",
    "    \n",
    "    return response, docs\n",
    "\n",
    "# Example usage\n",
    "video_url = \"https://youtu.be/LpVRn4Djj5s?si=3U7cU81vvu6RIK6\"\n",
    "db = create_db_from_youtube_video_url(video_url)\n",
    "query = \"How does the pump work?\"\n",
    "response, docs = get_response_from_query(db, query)\n",
    "\n",
    "# Print the response with a line width of 85 characters\n",
    "print(textwrap.fill(response, width=85))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a33c7-b652-42f2-beee-a15350f979fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
